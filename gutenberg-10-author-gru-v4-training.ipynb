{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "\n",
    "import glob\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import unicodedata\n",
    "import random\n",
    "import regex\n",
    "import spacy\n",
    "import string\n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "import time\n",
    "import timeit\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "from apex import amp\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchtext\n",
    "from torchtext.data import Field, BucketIterator, TabularDataset, Iterator\n",
    "from torch.optim import Adam, RMSprop\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp.max_length = 2000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_AMP = True\n",
    "DEVICE = torch.device('cuda:0' if USE_AMP else 'cpu')\n",
    "MODEL_NAME = 'gru-v4'\n",
    "MODEL_PATH = f'./saved-data/models/{MODEL_NAME}-state-dict.pt'\n",
    "MODEL_PATH2 = f'./saved-data/models/{MODEL_NAME}-final-state-dict.pt'\n",
    "GENERATE_SAMPLES = False\n",
    "SAMPLE_SIZE = 200\n",
    "AUTHORS = [\n",
    "    'Andrew Lang',\n",
    "    'Anthony Trollope',\n",
    "    'Baronness Orczy',\n",
    "    'Benjamin Disraeli',\n",
    "    'Bret Harte',\n",
    "    'Charles Darwin',\n",
    "    'Charles Dickens',\n",
    "    'Charles Kingsley',\n",
    "    'Charlotte Mary Yonge',\n",
    "    'Daniel Defoe',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Labeled Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GENERATE_SAMPLES:\n",
    "    paths = glob.glob('labeled-text/*')\n",
    "    paths.sort()\n",
    "    all_titles = [fn.split('/')[-1].split('___')[1][:-4] for fn in paths]\n",
    "    all_authors = [fn.split('/')[-1].split('___')[0] for fn in paths]\n",
    "    all_texts = [\n",
    "        open(path, errors='ignore', mode='r')\\\n",
    "        .read().replace('\\n', ' ').replace('\\r', '')\n",
    "             for path in paths\n",
    "    ]\n",
    "    \n",
    "    author_texts = {author:{'texts': [], 'train': [], 'val': [], 'test': []} for author in AUTHORS}\n",
    "    for author, text in zip(all_authors, all_texts):\n",
    "        if author in list(author_texts.keys()):\n",
    "            author_texts[author]['texts'].append(text)\n",
    "    \n",
    "    train_df = pd.DataFrame(columns=['text', 'author'])\n",
    "    val_df = pd.DataFrame(columns=['text', 'author'])\n",
    "    test_df = pd.DataFrame(columns=['text', 'author'])\n",
    "    for author in tqdm_notebook(AUTHORS):\n",
    "        num_of_texts = len(author_texts[author]['texts'])\n",
    "        train_count = int(0.8 * num_of_texts)\n",
    "        val_count = int(0.5 * (num_of_texts - train_count))\n",
    "        test_count = num_of_texts - train_count - val_count\n",
    "        \n",
    "        author_texts[author]['train'] = author_texts[author]['texts'][:train_count]\n",
    "        author_texts[author]['val'] = author_texts[author]['texts'][train_count:train_count+val_count]\n",
    "        author_texts[author]['test'] = author_texts[author]['texts'][train_count+val_count:]\n",
    "        \n",
    "        for doc in nlp.pipe(author_texts[author]['train'], disable=['tagger', 'parser', 'ner']):\n",
    "            train_df = pd.concat([train_df] + [pd.DataFrame(\n",
    "                    [[''.join(token.text_with_ws for token in doc[idx:idx+SAMPLE_SIZE]), author]], columns=['text', 'author']\n",
    "                ) for idx in range(0, len(doc)-SAMPLE_SIZE, SAMPLE_SIZE)], ignore_index=True)\n",
    "        for doc in nlp.pipe(author_texts[author]['val'], disable=['tagger', 'parser', 'ner']):\n",
    "            val_df = pd.concat([val_df] + [pd.DataFrame(\n",
    "                    [[''.join(token.text_with_ws for token in doc[idx:idx+SAMPLE_SIZE]), author]], columns=['text', 'author']\n",
    "                ) for idx in range(0, len(doc)-SAMPLE_SIZE, SAMPLE_SIZE)], ignore_index=True)\n",
    "        for doc in nlp.pipe(author_texts[author]['test'], disable=['tagger', 'parser', 'ner']):\n",
    "            test_df = pd.concat([test_df] + [pd.DataFrame(\n",
    "                    [[''.join(token.text_with_ws for token in doc[idx:idx+SAMPLE_SIZE]), author]], columns=['text', 'author']\n",
    "                ) for idx in range(0, len(doc)-SAMPLE_SIZE, SAMPLE_SIZE)], ignore_index=True)\n",
    "    \n",
    "    train_df.to_csv(f'saved-data/csv/{SAMPLE_SIZE}-token-train.csv', index=False)\n",
    "    val_df.to_csv(f'saved-data/csv/{SAMPLE_SIZE}-token-val.csv', index=False)\n",
    "    test_df.to_csv(f'saved-data/csv/{SAMPLE_SIZE}-token-test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    return [tok.text for tok in nlp.tokenizer(text)]\n",
    "\n",
    "BATCH_SIZE = 48\n",
    "VAL_BATCH_SIZE = 48\n",
    "TEXT = Field(sequential=True, tokenize=tokenizer, lower=True, batch_first=True)\n",
    "LABEL = Field(sequential=False, batch_first=True)\n",
    "\n",
    "train_df = pd.read_csv(f'saved-data/csv/{SAMPLE_SIZE}-token-train.csv')\n",
    "val_df = pd.read_csv(f'saved-data/csv/{SAMPLE_SIZE}-token-val.csv')\n",
    "val_df = val_df.sample(n=5000)\n",
    "test_df = pd.read_csv(f'saved-data/csv/{SAMPLE_SIZE}-token-test.csv')\n",
    "\n",
    "train_td, val_td, test_td = TabularDataset.splits(\n",
    "    path='saved-data/csv/', train=f'{SAMPLE_SIZE}-token-train.csv',\n",
    "    validation=f'{SAMPLE_SIZE}-token-val.csv', test=f'{SAMPLE_SIZE}-token-test.csv',\n",
    "    format='csv', skip_header=True, fields=[('text', TEXT), ('label', LABEL)])\n",
    "\n",
    "TEXT.build_vocab(train_td, min_freq=5)\n",
    "text_vocab = TEXT.vocab\n",
    "LABEL.build_vocab(train_td)\n",
    "label_vocab = LABEL.vocab\n",
    "\n",
    "train_iter, val_iter, test_iter = Iterator.splits(\n",
    "    (train_td, val_td, test_td),\n",
    "    sort_key=lambda x: len(x.text),\n",
    "    shuffle=True,\n",
    "    sort_within_batch=False,\n",
    "    batch_sizes=(BATCH_SIZE, VAL_BATCH_SIZE, VAL_BATCH_SIZE),\n",
    "    device=DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(labels, vocab_size):\n",
    "    one_hot = torch.zeros(labels.size(0), labels.size(1), vocab_size).to(DEVICE)\n",
    "    return one_hot.scatter_(dim=2, index=labels.unsqueeze(2), value=1)\n",
    "\n",
    "class GruWordTokenClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, num_layers, output_size, drop_prob, is_bidir):\n",
    "        super(GruWordTokenClassifier, self).__init__()\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.output_size = output_size\n",
    "        self.drop_prob = drop_prob\n",
    "        self.is_bidir = is_bidir\n",
    "        \n",
    "        self.gru = nn.GRU(vocab_size, hidden_size, num_layers, batch_first=True,\n",
    "                          dropout=drop_prob, bidirectional=is_bidir)\n",
    "        \n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        \n",
    "        if is_bidir:\n",
    "            self.fc = nn.Linear(hidden_size * 2, output_size)\n",
    "        else:\n",
    "            self.fc = nn.Linear(hidden_size, output_size)\n",
    "            \n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        if self.is_bidir:\n",
    "            hidden = weight.new(self.num_layers * 2, batch_size, self.hidden_size).zero_().to(DEVICE)\n",
    "        else:\n",
    "            hidden = weight.new(self.num_layers, batch_size, self.hidden_size).zero_().to(DEVICE)\n",
    "        return hidden\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len = x.shape\n",
    "        if seq_len > 200:\n",
    "            x = x[:, 0:200]\n",
    "            seq_len = x.shape[1]\n",
    "        \n",
    "        x_oh = one_hot(x, self.vocab_size)\n",
    "        hidden = self.init_hidden(batch_size)\n",
    "        \n",
    "        out, hidden = self.gru(x_oh, hidden)\n",
    "        out = out.transpose(0,1)\n",
    "        out = out[-1, :, :]\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        out = self.fc(out)\n",
    "        out = self.softmax(out)\n",
    "        \n",
    "        return out, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\")\n"
     ]
    }
   ],
   "source": [
    "model = GruWordTokenClassifier(\n",
    "    vocab_size=len(TEXT.vocab), hidden_size=512, num_layers=3,\n",
    "    output_size=len(AUTHORS)+1, drop_prob=0.5, is_bidir=False).to(DEVICE)\n",
    "\n",
    "optimizer = Adam(model.parameters(), eps=1e-4, weight_decay=1e-5)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', patience=4)\n",
    "criterion = torch.nn.CrossEntropyLoss().to(DEVICE)\n",
    "\n",
    "if USE_AMP:\n",
    "    model, optimizer = amp.initialize(\n",
    "        model, optimizer, opt_level='O1', keep_batchnorm_fp32=None, loss_scale='dynamic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/8... Step: 0... Loss: 2.367469... Val Loss: 2.922967... Val Acc: 0.160588\n",
      "Validation loss decreased (2.922967 --> 2.922967). Saving model...\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2048.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1024.0\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 512.0\n",
      "Epoch: 1/8... Step: 500... Loss: 1.752692... Val Loss: 1.833199... Val Acc: 0.349231\n",
      "Validation loss decreased (2.922967 --> 1.833199). Saving model...\n",
      "Epoch: 1/8... Step: 1000... Loss: 1.093027... Val Loss: 1.320352... Val Acc: 0.523622\n",
      "Validation loss decreased (1.833199 --> 1.320352). Saving model...\n",
      "Epoch: 1/8... Step: 1500... Loss: 0.310736... Val Loss: 0.734693... Val Acc: 0.782815\n",
      "Validation loss decreased (1.320352 --> 0.734693). Saving model...\n",
      "Epoch: 1/8... Step: 2000... Loss: 0.183924... Val Loss: 0.644001... Val Acc: 0.803277\n",
      "Validation loss decreased (0.734693 --> 0.644001). Saving model...\n",
      "Epoch: 1/8... Step: 2500... Loss: 0.197705... Val Loss: 0.566428... Val Acc: 0.828788\n",
      "Validation loss decreased (0.644001 --> 0.566428). Saving model...\n",
      "Epoch: 1/8... Step: 3000... Loss: 0.343537... Val Loss: 0.630819... Val Acc: 0.821307\n",
      "Epoch: 1/8... Step: 3500... Loss: 0.345635... Val Loss: 0.653420... Val Acc: 0.800696\n",
      "Epoch: 1... Loss: 0.007846... Time: 103:19\n",
      "Epoch: 2/8... Step: 4000... Loss: 0.217978... Val Loss: 0.620897... Val Acc: 0.842816\n",
      "Epoch: 2/8... Step: 4500... Loss: 0.213676... Val Loss: 0.632685... Val Acc: 0.833352\n",
      "Epoch: 2/8... Step: 5000... Loss: 0.179497... Val Loss: 0.542117... Val Acc: 0.850522\n",
      "Validation loss decreased (0.566428 --> 0.542117). Saving model...\n",
      "Epoch: 2/8... Step: 5500... Loss: 0.143662... Val Loss: 0.593704... Val Acc: 0.840833\n",
      "Epoch: 2/8... Step: 6000... Loss: 0.058062... Val Loss: 0.493372... Val Acc: 0.860472\n",
      "Validation loss decreased (0.542117 --> 0.493372). Saving model...\n",
      "Epoch: 2/8... Step: 6500... Loss: 0.084219... Val Loss: 0.632871... Val Acc: 0.839823\n",
      "Epoch: 2/8... Step: 7000... Loss: 0.098141... Val Loss: 0.524561... Val Acc: 0.860996\n",
      "Epoch: 2/8... Step: 7500... Loss: 0.306216... Val Loss: 0.743689... Val Acc: 0.800584\n",
      "Epoch: 2... Loss: 0.107477... Time: 104:17\n",
      "Epoch: 3/8... Step: 8000... Loss: 0.068896... Val Loss: 0.843070... Val Acc: 0.815584\n",
      "Epoch: 3/8... Step: 8500... Loss: 0.019138... Val Loss: 0.629745... Val Acc: 0.850709\n",
      "Epoch: 3/8... Step: 9000... Loss: 0.001638... Val Loss: 0.547364... Val Acc: 0.874799\n",
      "Epoch: 3/8... Step: 9500... Loss: 0.032225... Val Loss: 0.526666... Val Acc: 0.878315\n",
      "Epoch: 3/8... Step: 10000... Loss: 0.001499... Val Loss: 0.510825... Val Acc: 0.880036\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "Epoch: 3/8... Step: 10500... Loss: 0.001039... Val Loss: 0.506607... Val Acc: 0.881757\n",
      "Epoch: 3/8... Step: 11000... Loss: 0.042162... Val Loss: 0.529080... Val Acc: 0.876183\n",
      "Epoch: 3/8... Step: 11500... Loss: 0.010332... Val Loss: 0.513718... Val Acc: 0.880934\n",
      "Epoch: 3... Loss: 0.001353... Time: 104:49\n",
      "Epoch: 4/8... Step: 12000... Loss: 0.000659... Val Loss: 0.509244... Val Acc: 0.881570\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "Epoch: 4/8... Step: 12500... Loss: 0.015545... Val Loss: 0.511712... Val Acc: 0.881158\n",
      "Epoch: 4/8... Step: 13000... Loss: 0.002102... Val Loss: 0.508521... Val Acc: 0.883253\n",
      "Epoch: 4/8... Step: 13500... Loss: 0.020863... Val Loss: 0.506229... Val Acc: 0.883477\n",
      "Epoch: 4/8... Step: 14000... Loss: 0.000438... Val Loss: 0.504976... Val Acc: 0.883851\n",
      "Epoch: 4/8... Step: 14500... Loss: 0.048610... Val Loss: 0.505628... Val Acc: 0.883664\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "Epoch: 4/8... Step: 15000... Loss: 0.013735... Val Loss: 0.508603... Val Acc: 0.883365\n",
      "Epoch: 4/8... Step: 15500... Loss: 0.000911... Val Loss: 0.510236... Val Acc: 0.883290\n",
      "Epoch: 4... Loss: 0.030312... Time: 105:5\n",
      "Epoch: 5/8... Step: 16000... Loss: 0.001505... Val Loss: 0.509959... Val Acc: 0.883627\n",
      "Epoch: 5/8... Step: 16500... Loss: 0.000915... Val Loss: 0.510145... Val Acc: 0.883552\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "Epoch: 5/8... Step: 17000... Loss: 0.091564... Val Loss: 0.510159... Val Acc: 0.883627\n",
      "Epoch: 5/8... Step: 17500... Loss: 0.001308... Val Loss: 0.510526... Val Acc: 0.883590\n",
      "Epoch: 5/8... Step: 18000... Loss: 0.004848... Val Loss: 0.510705... Val Acc: 0.883590\n",
      "Epoch: 5/8... Step: 18500... Loss: 0.010160... Val Loss: 0.510532... Val Acc: 0.883477\n",
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "Epoch: 5/8... Step: 19000... Loss: 0.009042... Val Loss: 0.510547... Val Acc: 0.883515\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-17453a82eb12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mUSE_AMP\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mscaled_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                 \u001b[0mscaled_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mlve-10.1/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mlve-10.1/lib/python3.7/site-packages/apex/amp/handle.py\u001b[0m in \u001b[0;36mscale_loss\u001b[0;34m(loss, optimizers, loss_id, model, delay_unscale, delay_overflow_check)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mloss_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_overflow_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_post_amp_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_scaler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_amp_stash\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams_have_scaled_gradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0;31m# For future fused optimizers that enable sync-free dynamic loss scaling,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mlve-10.1/lib/python3.7/site-packages/apex/amp/_process_optimizer.py\u001b[0m in \u001b[0;36mpost_backward_no_master_weights\u001b[0;34m(self, scaler)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstashed_grads\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msplit_types\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0mpost_backward_models_are_masters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstashed_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mlve-10.1/lib/python3.7/site-packages/apex/amp/_process_optimizer.py\u001b[0m in \u001b[0;36mpost_backward_models_are_masters\u001b[0;34m(scaler, params, stashed_grads, scale_override)\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0mstashed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                 \u001b[0mgrads_needing_unscale_with_stash\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m                 scale_override=(grads_have_scale, stashed_have_scale, out_scale))\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;31m# Clear the stash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mlve-10.1/lib/python3.7/site-packages/apex/amp/scaler.py\u001b[0m in \u001b[0;36munscale_with_stashed\u001b[0;34m(self, model_grads, stashed_master_grads, master_grads, scale_override)\u001b[0m\n\u001b[1;32m    182\u001b[0m                                              \u001b[0mmaster_grads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                                              \u001b[0mout_scale\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mgrads_have_scale\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m                                              out_scale/stashed_have_scale)\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;31m# Defer to update_scale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mlve-10.1/lib/python3.7/site-packages/apex/amp/scaler.py\u001b[0m in \u001b[0;36munscale_with_stashed_python\u001b[0;34m(self, model_grads, stashed_master_grads, master_grads, a, b)\u001b[0m\n\u001b[1;32m    146\u001b[0m                                                                  \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m                                                                  \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m                                                                  self.dynamic)\n\u001b[0m\u001b[1;32m    149\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_overflow\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamic\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mlve-10.1/lib/python3.7/site-packages/apex/amp/scaler.py\u001b[0m in \u001b[0;36maxpby_check_overflow_python\u001b[0;34m(model_grad, stashed_grad, master_grad, a, b, check_overflow)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# Exception handling for 18.04 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcheck_overflow\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mcpu_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcpu_sum\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inf'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcpu_sum\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inf'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcpu_sum\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mcpu_sum\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 8\n",
    "step_count = 0\n",
    "val_loss_min = None\n",
    "hist_dict = {'steps':[], 'loss':[], 'val_loss':[], 'val_acc':[]}\n",
    "for epoch in range(n_epochs):\n",
    "    start = timeit.default_timer()\n",
    "    \n",
    "    for data in train_iter:\n",
    "        inputs, labels = data.text.to(DEVICE), data.label.to(DEVICE)\n",
    "        model.zero_grad()\n",
    "        output, hidden = model(inputs)\n",
    "        loss = criterion(output, labels)\n",
    "        \n",
    "        if USE_AMP:\n",
    "            with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                scaled_loss.backward()\n",
    "        else:\n",
    "            loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        # Validate model every 500 batches\n",
    "        if step_count % 500 == 0:\n",
    "            val_losses = []\n",
    "            val_acc = 0\n",
    "            \n",
    "            model.eval()\n",
    "            for val_data in val_iter:\n",
    "                with torch.no_grad():\n",
    "                    val_inputs, val_labels = val_data.text.to(DEVICE), val_data.label.to(DEVICE)\n",
    "                    val_out, val_hidden = model(val_inputs)\n",
    "                    val_loss = criterion(val_out, val_labels)\n",
    "                    val_losses.append(val_loss.item())\n",
    "                    val_acc += (val_out.argmax(1) == val_labels).sum().item()\n",
    "            model.train()\n",
    "\n",
    "            val_loss_mean = np.mean(val_losses)\n",
    "            val_acc = val_acc / (len(val_iter.dataset.examples))\n",
    "            scheduler.step(val_loss_mean)\n",
    "\n",
    "            hist_dict['steps'].append(step_count)\n",
    "            hist_dict['loss'].append(loss.item())\n",
    "            hist_dict['val_loss'].append(val_loss_mean)\n",
    "            hist_dict['val_acc'].append(val_acc)\n",
    "\n",
    "            print('Epoch: {}/{}...'.format(epoch+1, n_epochs),\n",
    "                  'Step: {}...'.format(step_count),\n",
    "                  'Loss: {:.6f}...'.format(loss.item()),\n",
    "                  'Val Loss: {:.6f}...'.format(val_loss_mean),\n",
    "                  'Val Acc: {:.6f}'.format(val_acc))\n",
    "\n",
    "            if val_loss_min is None:\n",
    "                val_loss_min = val_loss_mean\n",
    "\n",
    "            if val_loss_mean <= val_loss_min:\n",
    "                print('Validation loss decreased ({:.6f} --> {:.6f}). Saving model...'.format(val_loss_min, val_loss_mean))\n",
    "                torch.save(model.state_dict(), MODEL_PATH)\n",
    "                val_loss_min = val_loss_mean\n",
    "            \n",
    "        step_count += 1\n",
    "    \n",
    "    seconds = int(timeit.default_timer() - start)\n",
    "    minutes = seconds // 60\n",
    "    print(f'Epoch: {epoch + 1}... Loss: {loss.item():.6f}... Time: {minutes}:{seconds % 60}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist_dict['steps'], hist_dict['loss'], 'bo', label='Training')\n",
    "plt.plot(hist_dict['steps'], hist_dict['val_loss'], 'b', label='Validation')\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist_dict['steps'], hist_dict['val_acc'], 'b', label='Validation')\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(model.state_dict(), MODEL_PATH2)\n",
    "model = GruWordTokenClassifier(\n",
    "    vocab_size=len(TEXT.vocab), hidden_size=512, num_layers=3,\n",
    "    output_size=len(AUTHORS)+1, drop_prob=0.5, is_bidir=False).to(DEVICE)\n",
    "model.load_state_dict(torch.load(MODEL_PATH2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cb91d7368d9451a93851f7cbf3dcdf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=609), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.8447562018819503\n"
     ]
    }
   ],
   "source": [
    "def test(model, tt_iter):\n",
    "    acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    for data in tqdm_notebook(tt_iter):\n",
    "        with torch.no_grad():\n",
    "            inputs, labels = data.text.to(DEVICE), data.label.to(DEVICE)\n",
    "            output, hidden = model(inputs)\n",
    "            acc += (output.argmax(1) == labels).sum().item()\n",
    "    model.train()\n",
    "    \n",
    "    return acc / len(tt_iter.dataset.examples)\n",
    "\n",
    "print(test(model, test_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "356d6273e33f40559906c01d6beb2e7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=609), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.8247733105218135\n"
     ]
    }
   ],
   "source": [
    "model_loaded = GruWordTokenClassifier(\n",
    "    vocab_size=len(TEXT.vocab), hidden_size=512, num_layers=3,\n",
    "    output_size=len(AUTHORS)+1, drop_prob=0.5, is_bidir=False).to(DEVICE)\n",
    "model_loaded.load_state_dict(torch.load(MODEL_PATH))\n",
    "\n",
    "print(test(model_loaded, test_iter))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
